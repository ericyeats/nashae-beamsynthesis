{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113e4510",
   "metadata": {},
   "source": [
    "# CelebA Eval\n",
    "### Overview\n",
    "This script is used to evaluate a saved CelebA model qualitatively (with latent traversals) and quantitatively (using the TAD metric). The script will compare original data with reconstructions, generate latent traversals, and generate a TAD score at the end.\n",
    "\n",
    "### Instructions\n",
    "Adjust the hyperparameters and PATH below to match the hyperparameters and path of the saved model that you would like to evaluate. Then hit \"Restart and Run All\" on the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SELECT EVALUATION PARAMETERS ##################\n",
    "\n",
    "from ae_utils_exp import celeba_norm, celeba_inorm\n",
    "n_lat = 32\n",
    "use_vae = False\n",
    "PATH = \"./models/celeba_ae_lr1e-3_seed55_ar0.2.pt\"\n",
    "\n",
    "from ae_utils_exp import B_TCVAE as VAE_BASED_MODEL # change <model> in \".... import <model> as ....\"\n",
    "### options: VAE (for VAE, BetaVAE), FACTOR_VAE, or B_TCVAE (for BetaTCVAE)\n",
    "\n",
    "#################################################\n",
    "from ae_utils_exp import AutoEncoder\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "from architectures import enc_celeba_small_vae as enc_vae\n",
    "from architectures import enc_celeba_small as enc\n",
    "from architectures import dec_celeba_small as dec\n",
    "ae = None\n",
    "\n",
    "if not use_vae:\n",
    "    ae = AutoEncoder(celeba_norm, enc(lat=n_lat, inp_chan=3), dec(lat=n_lat, inp_chan=3), \\\n",
    "                     device, z_dim=n_lat, inp_inorm=celeba_inorm)\n",
    "else:\n",
    "    ae = VAE_BASED_MODEL(celeba_norm, enc_vae(lat=n_lat, inp_chan=3), dec(lat=n_lat, inp_chan=3), \\\n",
    "                         device, z_dim=n_lat, inp_inorm=celeba_inorm)\n",
    "\n",
    "\n",
    "ae.load_state_dict(torch.load(PATH))\n",
    "ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 30 # FIXED AT 30 FOR ALL EXPERIMENTS\n",
    "import random\n",
    "random.seed(seed)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ae_utils_exp import multi_t, LatentClass, aurocs_search, tags\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9756f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CelebA\n",
    "import torchvision.transforms as tforms\n",
    "\n",
    "tform = tforms.Compose([tforms.Resize(96), tforms.CenterCrop(64), tforms.ToTensor()])\n",
    "\n",
    "eval_bs = 1000\n",
    "# set up dataset for eval\n",
    "dataset_eval = CelebA(root='../beamsynthesizer/data', split='all', target_type='attr', download=False, transform=tform)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=eval_bs, shuffle=True, drop_last=False)\n",
    "data, targ = next(iter(dataloader_eval))\n",
    "fig, ax = plt.subplots(2, 10, figsize=(20, 4))\n",
    "for i in range(20):\n",
    "    ind = i // 10, i % 10\n",
    "    ax[ind].imshow(multi_t(data[i], 0, 2))\n",
    "    ax[ind].set_title(targ[i][20].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare originals with reconstructions\n",
    "plt_batch_size=500\n",
    "num_to_plot=20\n",
    "z_scores, z_pred_scores, inp, rec = ae.record_latent_space(dataset_eval, batch_size=plt_batch_size, n_batches=5)\n",
    "\n",
    "inp = multi_t(inp, 1, 3).clamp(0, 1).cpu().numpy()\n",
    "rec = multi_t(rec, 1, 3).clamp(0, 1).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, num_to_plot, figsize=(20, 4))\n",
    "for i in range(num_to_plot):\n",
    "    axes[0][i].imshow(inp[i])\n",
    "    axes[1][i].imshow(rec[i])\n",
    "    axes[0][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    axes[1][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ae_utils_exp import InvNorm\n",
    "\n",
    "invn = celeba_inorm\n",
    "\n",
    "\n",
    "# determine base z_scores\n",
    "ind = 6\n",
    "z_base = z_scores[ind]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axes[0].imshow(inp[ind])\n",
    "axes[0].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "axes[1].imshow(rec[ind])\n",
    "axes[1].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate latent traversals\n",
    "# decode\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 24))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i].min()\n",
    "        _max = z_scores[:, i].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min >= 0.2:\n",
    "                z = z_base.clone()\n",
    "                z[i] = variation[j]\n",
    "                im = multi_t(invn(ae.dec(z.to(ae.device))), 1, 3).clamp(0, 1).squeeze().cpu().numpy()\n",
    "                axes[i][j].imshow(im)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate latent traversals\n",
    "# decode\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 24))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i + ae.z_dim//2].min()\n",
    "        _max = z_scores[:, i + ae.z_dim//2].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min >= 0.2:\n",
    "                z = z_base.clone()\n",
    "                z[i + ae.z_dim//2] = variation[j]\n",
    "                im = multi_t(invn(ae.dec(z.to(ae.device))), 1, 3).clamp(0,1).squeeze().cpu().numpy()\n",
    "                axes[i][j].imshow(im)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_result, base_rates_raw, targ = aurocs_search(dataloader_eval, ae)\n",
    "base_rates = base_rates_raw.where(base_rates_raw <= 0.5, 1. - base_rates_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab198bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mutual information shared between attributes\n",
    "# determine which share a lot of information with each other\n",
    "with torch.no_grad():\n",
    "    not_targ = 1 - targ\n",
    "    j_prob = lambda x, y: torch.logical_and(x, y).sum() / x.numel()\n",
    "    mi = lambda jp, px, py: 0. if jp == 0. or px == 0. or py == 0. else jp*torch.log(jp/(px*py))\n",
    "\n",
    "    # Compute the Mutual Information (MI) between the labels\n",
    "    mi_mat = torch.zeros((40, 40))\n",
    "    for i in range(40):\n",
    "        # get the marginal of i\n",
    "        i_mp = targ[:, i].sum() / targ.shape[0]\n",
    "        for j in range(40):\n",
    "            j_mp = targ[:, j].sum() / targ.shape[0]\n",
    "            # get the joint probabilities of FF, FT, TF, TT\n",
    "            # FF\n",
    "            jp = j_prob(not_targ[:, i], not_targ[:, j])\n",
    "            pi = 1. - i_mp\n",
    "            pj = 1. - j_mp\n",
    "            mi_mat[i][j] += mi(jp, pi, pj)\n",
    "            # FT\n",
    "            jp = j_prob(not_targ[:, i], targ[:, j])\n",
    "            pi = 1. - i_mp\n",
    "            pj = j_mp\n",
    "            mi_mat[i][j] += mi(jp, pi, pj)\n",
    "            # TF\n",
    "            jp = j_prob(targ[:, i], not_targ[:, j])\n",
    "            pi = i_mp\n",
    "            pj = 1. - j_mp\n",
    "            mi_mat[i][j] += mi(jp, pi, pj)\n",
    "            # TT\n",
    "            jp = j_prob(targ[:, i], targ[:, j])\n",
    "            pi = i_mp\n",
    "            pj = j_mp\n",
    "            mi_mat[i][j] += mi(jp, pi, pj)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    im = ax[0].imshow(mi_mat)\n",
    "    fig.colorbar(im, ax=ax[0], shrink=0.6)\n",
    "    mi_mat_ent_norm = mi_mat/mi_mat.diag().unsqueeze(1)\n",
    "    im = ax[1].imshow(mi_mat_ent_norm)\n",
    "    fig.colorbar(im, ax=ax[1], shrink=0.6)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    mi_comp = (mi_mat.sum(dim=1) - mi_mat.diag())/mi_mat.diag()\n",
    "    plt.bar(range(len(tags)), mi_comp, tick_label=tags)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Total Mutual Information\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    mi_maxes, mi_inds = (mi_mat * (1 - torch.eye(40))).max(dim=1)\n",
    "    ent_red_prop = 1. - (mi_mat.diag() - mi_maxes) / mi_mat.diag()\n",
    "    plt.bar(range(len(tags)), ent_red_prop, tick_label=tags)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Proportion of Entropy Reduced by Another Trait\")\n",
    "    plt.grid(axis='y')\n",
    "    print(mi_mat.diag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab67397",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 5, figsize=(16, 16))\n",
    "# print the ind, tag, max auroc, arg max auroc, norm_diff\n",
    "max_aur, argmax_aur = torch.max(au_result.clone(), dim=1)\n",
    "norm_diffs = torch.zeros(40)\n",
    "aurs_diffs = torch.zeros(40)\n",
    "for ind, tag, max_a, argmax_a, aurs in zip(range(40), tags, max_aur.clone(), argmax_aur.clone(), au_result.clone()):\n",
    "    norm_aurs = (aurs.clone() - 0.5) / (aurs.clone()[argmax_a] - 0.5)\n",
    "    aurs_next = aurs.clone()\n",
    "    aurs_next[argmax_a] = 0.0\n",
    "    aurs_diff = max_a - aurs_next.max()\n",
    "    aurs_diffs[ind] = aurs_diff\n",
    "    norm_aurs[argmax_a] = 0.0\n",
    "    norm_diff = 1. - norm_aurs.max()\n",
    "    norm_diffs[ind] = norm_diff\n",
    "    print(\"{}\\t\\t Lat: {}\\t Max: {:1.3f}\\t ND: {:1.3f}\".format(tag, argmax_a.item(), max_a.item(), norm_diff.item()))\n",
    "    plt_ind = ind//5, ind%5\n",
    "    ax[plt_ind].set_ylim((0.5, max_a.item() + 0.05))\n",
    "    ax[plt_ind].set_title(tag)\n",
    "    ax[plt_ind].set_ylabel(\"AUROC\")\n",
    "    ax[plt_ind].set_xlabel(\"Latent Variable\")\n",
    "    ax[plt_ind].bar(range(aurs.shape[0]), aurs)\n",
    "    ax[plt_ind].grid(which='both', axis='y')\n",
    "    assert aurs.max() == max_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how prevalent are each of the attributes\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.ylim((0.0, 0.5))\n",
    "plt.title(\"Base Rates (Absolute)\")\n",
    "plt.ylabel(\"Base Rate\")\n",
    "plt.xlabel(\"Attribute\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(range(len(tags)), base_rates, tick_label=tags)\n",
    "plt.grid(which='both', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum AUROCS for each attribute\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.ylim((0.5, 1.0))\n",
    "plt.title(\"Max AUROCS\")\n",
    "plt.ylabel(\"AUROC\")\n",
    "plt.xlabel(\"Attribute\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(range(max_aur.shape[0]), max_aur, tick_label=tags)\n",
    "plt.grid(which='both', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_plot = torch.utils.data.DataLoader(dataset_eval, batch_size=eval_bs, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638e3a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose an Attribute to run through the Decoder\n",
    "attr_index = 5\n",
    "ind_max = argmax_aur[attr_index]\n",
    "\n",
    "invn = celeba_inorm\n",
    "num = 8\n",
    "# using 10 samples from the dataloader, plot 10 rows of the varied attributes\n",
    "# decode\n",
    "fig, axes = plt.subplots(num, num, figsize=(16, 16))\n",
    "ae.to(device)\n",
    "with torch.no_grad():\n",
    "    data, targ = next(iter(dataloader_plot))\n",
    "    data = data.to(device)\n",
    "    out = ae(data)\n",
    "    _min = ae.z.min(dim=0)[0]\n",
    "    _max = ae.z.max(dim=0)[0]\n",
    "    variation = torch.linspace(_min[ind_max], _max[ind_max], steps=num)\n",
    "    for i in range(num):\n",
    "        z_base = ae.z[i + 41]\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            z = z_base.clone()\n",
    "            z[ind_max] = variation[j]\n",
    "            im = multi_t(invn(ae.dec(z.to(ae.device))), 1, 3).clamp(0, 1).squeeze().cpu().numpy()\n",
    "            axes[i][j].imshow(im)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.75\n",
    "ent_red_thresh = 0.2\n",
    "\n",
    "# calculate Average Norm AUROC Diff when best detector score is at a certain threshold\n",
    "filt = (max_aur >= thresh).logical_and(ent_red_prop <= ent_red_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031300ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm_diffs_filt = norm_diffs[filt]\n",
    "print(len(norm_diffs_filt))\n",
    "for ind in torch.arange(filt.shape[0])[filt]:\n",
    "    print(tags[ind], argmax_aur[ind].item())\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.ylim((0.0, 1.0))\n",
    "plt.title(\"Average Norm AUROC Diff: {:1.3f} at Thresh: {:1.2f}\".format(norm_diffs_filt.mean(), thresh))\n",
    "plt.ylabel(\"Normed AUROC Difference\")\n",
    "plt.xlabel(\"Attribute\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(range(norm_diffs.shape[0]), norm_diffs, tick_label=tags)\n",
    "plt.grid(which='both', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0d1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate Average Norm AUROC Diff when best detector score is at a certain threshold\n",
    "aurs_diffs_filt = aurs_diffs[filt]\n",
    "print(len(aurs_diffs_filt))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.ylim((0.0, 1.0))\n",
    "plt.title(\"Total AUROC Diff: {:1.3f} at Thresh: {:1.2f}\".format(aurs_diffs_filt.sum(), thresh))\n",
    "plt.ylabel(\"AUROC Difference\")\n",
    "plt.xlabel(\"Attribute\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(range(aurs_diffs.shape[0]), aurs_diffs, tick_label=tags)\n",
    "plt.grid(which='both', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a00d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TAD SCORE: \", aurs_diffs_filt.sum().item(), \"Attributes Captured: \", len(aurs_diffs_filt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397da1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
