{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0044ace5",
   "metadata": {},
   "source": [
    "# NashAE dSprites\n",
    "### Overview\n",
    "This script is used to train a NashAE or AE (NashAE, $\\lambda=0$) on the dSprites dataset, then evaluate it. The script will train a NashAE on a fixed amount of data using the hyperparameters defined in the cell below. The script will train the network with the given hyperparameters, compare original data with reconstructions, plot true latent variables against their predictions, create images of latent traversals, and evaluate the model using the BetaVAE metric.\n",
    "\n",
    "### Instructions\n",
    "Set hyperparameters for the run in the cell below. Then, hit Run All on the jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe16cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = random.randint(0, 1000)\n",
    "random.seed(seed)\n",
    "\n",
    "### SELECT HYPERPARAMETERS FOR THE MODEL ###\n",
    "\n",
    "ar = 0.008 # adversarial ratio (\\lambda)\n",
    "n_lat = 10 # AE bottleneck size (m)\n",
    "batch_size = 200 # batch size used for training\n",
    "lr = 0.001 # learning rate used for training\n",
    "\n",
    "\n",
    "print(\"Seed: \", seed)\n",
    "print(\"Batch Size: \", batch_size)\n",
    "print(\"LR: \", lr)\n",
    "print(\"AdvRatio: \", ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ae_utils_exp import s_init, AutoEncoder, InpNorm1D\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00559994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsprites import DSPRITES\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "ten_type = lambda x: torch.tensor(x, dtype=torch.float)\n",
    "flatten = lambda x: x.view(-1)\n",
    "chan_insert = lambda x: x.unsqueeze(0)\n",
    "\n",
    "dataset = DSPRITES(path=\"../beamsynthesizer/data/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\", transform=Compose([ten_type, chan_insert]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ident = torch.nn.Identity()\n",
    "from architectures import enc_dsprites_fc as enc\n",
    "from architectures import dec_dsprites_fc as dec\n",
    "ae = AutoEncoder(ident, enc(lat=n_lat), dec(lat=n_lat), device, z_dim=n_lat, inp_inorm=ident,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fb753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_loss, adv_loss, pred_loss = \\\n",
    "    ae.fit(dataset, 200, preds_train_iters=5, batch_per_group=20, batch_size=batch_size, lr=lr, pred_lr=0.01, ar=ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 3))\n",
    "# plot the loss curves on a log scale\n",
    "ax[0].set_ylabel(\"$log_{10}$(MSE Loss)\")\n",
    "ax[0].set_xlabel(\"Group\")\n",
    "ax[0].plot(np.log10(rec_loss), linewidth=2, label='Reconstruction')\n",
    "ax[0].plot(np.log10(pred_loss), linewidth=2, label='Predictor')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, which='both', ls='-')\n",
    "\n",
    "ax[1].set_ylabel(\"$log_{10}$ (Abs. Mean Cov.)\")\n",
    "ax[1].set_xlabel(\"Group\")\n",
    "ax[1].plot(np.log10(adv_loss.abs()/ae.z_dim), linewidth=2, label='Adversarial')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, which='both', ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some reconstructions of the data\n",
    "plt_batch_size=200\n",
    "num_to_plot=20\n",
    "z_scores, z_pred_scores, inp, rec = ae.record_latent_space(dataset, batch_size=plt_batch_size, n_batches=5)\n",
    "\n",
    "inp = inp.view(-1, 64, 64).cpu().numpy()\n",
    "rec = rec.view(-1, 64, 64).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, num_to_plot, figsize=(20, 4))\n",
    "for i in range(num_to_plot):\n",
    "    axes[0][i].imshow(inp[i], cmap='gray')\n",
    "    axes[1][i].imshow(rec[i], cmap='gray')\n",
    "    axes[0][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    axes[1][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of learned latent features\n",
    "_mins, _min_indices = z_scores.min(dim=0)\n",
    "_maxes, _max_indices = z_scores.max(dim=0)\n",
    "diff = _maxes - _mins\n",
    "print(\"NashAE Count: \", (diff > 0.2).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot true latent variables vs their predictions; calculate r^2 statistic for each pair\n",
    "from ae_utils_exp import covariance\n",
    "# plot the latent space against itself\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for ind in range(ae.z_dim):\n",
    "    i = ind // 5\n",
    "    j = ind % 5\n",
    "    axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    axes[i][j].scatter(z_scores[..., ind], z_pred_scores[..., ind])\n",
    "    axes[i][j].set_xlim((-0.05, 1.05))\n",
    "    axes[i][j].set_ylim((-0.05, 1.05))\n",
    "    cov = covariance(z_scores[..., ind], z_pred_scores[..., ind]).item()\n",
    "    std = z_scores[..., ind].std(dim=0).item()\n",
    "    std_p = z_pred_scores[..., ind].std(dim=0).item()\n",
    "    rho2 = 0.\n",
    "    if std > 0. and std_p > 0.:\n",
    "        rho2 = (cov/(std*std_p))**2\n",
    "    axes[i][j].set_title(\"R2: {:1.3f}\".format(rho2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06883920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine base z_scores\n",
    "ind = 0\n",
    "z_base = z_scores[ind]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axes[0].imshow(inp[ind], cmap='gray')\n",
    "axes[0].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "axes[1].imshow(rec[ind], cmap='gray')\n",
    "axes[1].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92be45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# decode\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 8))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i].min()\n",
    "        _max = z_scores[:, i].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min > 0.2:\n",
    "                z = z_base.clone()\n",
    "                z[i] = variation[j]\n",
    "                im = dsprites_inorm(ae.dec(z.to(ae.device))).view(64, 64).cpu().numpy()\n",
    "                axes[i][j].imshow(im, cmap='gray', vmin=0., vmax=1.)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 8))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i + ae.z_dim//2].min()\n",
    "        _max = z_scores[:, i + ae.z_dim//2].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min > 0.2:\n",
    "                z = z_base.clone()\n",
    "                z[i + ae.z_dim//2] = variation[j]\n",
    "                im = dsprites_inorm(ae.dec(z.to(ae.device))).view(64, 64).cpu().numpy()\n",
    "                axes[i][j].imshow(im, cmap='gray', vmin=0., vmax=1.)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the BetaVAE disentanglement metric\n",
    "from ae_utils_exp import DisentanglementMetric as DM\n",
    "dm = DM(n_lat, 4, lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0df0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the disentanglement metric linear classifier\n",
    "n_groups = 3000\n",
    "batch_per_group = 20\n",
    "bsize = 100\n",
    "losses = torch.zeros(n_groups)\n",
    "for i in range(n_groups):\n",
    "    loss = 0.\n",
    "    for j in range(batch_per_group):\n",
    "        # construct the batch\n",
    "        # randomly choose a data generating factor to hold constant, and create batches\n",
    "        const_dgf, batch_tup1, batch_tup2 = dataset.sample_latent_dm(bsize)\n",
    "        # push batches through the autoencoder\n",
    "        z1 = ae.z_act(ae.enc(ae.inp_norm(batch_tup1[0].to(device)))).detach()\n",
    "        z2 = ae.z_act(ae.enc(ae.inp_norm(batch_tup2[0].to(device)))).detach()\n",
    "        z_diff = (z1 - z2).abs()\n",
    "        # train on batch. min dgf is 2\n",
    "        loss += dm.fit_batch(const_dgf - 2, z_diff.cpu())\n",
    "    losses[i] = loss/batch_per_group\n",
    "    if i % 500 == 0:\n",
    "        print(i)\n",
    "    if i == int(0.95*n_groups):\n",
    "        dm.set_lr(0.05)\n",
    "plt.figure()\n",
    "plt.plot(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "bsize = 100\n",
    "n_correct = 0\n",
    "for i in range(n_iterations):\n",
    "    # construct the batch\n",
    "    # randomly choose a data generating factor to hold constant, and create batches\n",
    "    const_dgf, batch_tup1, batch_tup2 = dataset.sample_latent_dm(bsize)\n",
    "    # push batches through the autoencoder\n",
    "    z1 = ae.z_act(ae.enc(ae.inp_norm(batch_tup1[0].to(device)))).detach()\n",
    "    z2 = ae.z_act(ae.enc(ae.inp_norm(batch_tup2[0].to(device)))).detach()\n",
    "    z_diff = (z1 - z2).abs()\n",
    "    # batch is now constructed\n",
    "    prediction = dm(z_diff.mean(dim=0).unsqueeze(0).cpu())\n",
    "    n_correct += 1. if prediction == const_dgf - 2 else 0.\n",
    "print(\"Acc: {:1.2f}\".format(n_correct/n_iterations*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Seed: \", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b709798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5347f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
