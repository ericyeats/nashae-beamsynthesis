{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df007fa",
   "metadata": {},
   "source": [
    "# VAE dSprites\n",
    "### Overview\n",
    "This script is used to run all dSprites tests involving VAE (BetaVAE, $\\beta=1$), BetaVAE, FactorVAE, or BetaTCVAE. The script will train a VAE-based model on a fixed amount of data using the hyperparameters defined in the cell below. The script will generate latent traversals, compare original data against reconstructions of data, and evaluate the latent space using the BetaVAE disentanglement metric.\n",
    "\n",
    "### Instructions\n",
    "Set hyperparameters for the run in the cell below. Then, hit Run All on the jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe16cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = random.randint(0, 1000)\n",
    "random.seed(seed)\n",
    "\n",
    "#### SELECT HYPERPARAMETERS FOR THE MODEL #######\n",
    "\n",
    "from ae_utils_exp import B_TCVAE as VAE_BASED_MODEL # change <model> in \".... import <model> as ....\"\n",
    "### options: VAE (for VAE, BetaVAE), FACTOR_VAE, or B_TCVAE (for BetaTCVAE)\n",
    "\n",
    "beta = 1. # beta, used for disentanglement\n",
    "n_lat = 10 # VAE bottleneck size (m)\n",
    "batch_size = 200 # batch size used for training\n",
    "lr = 0.001 # learning rate used for training\n",
    "\n",
    "print(\"Seed: \", seed)\n",
    "print(\"Batch Size: \", batch_size)\n",
    "print(\"LR: \", lr)\n",
    "print(\"Beta: \", beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import DatasetFolder\n",
    "import matplotlib.pyplot as plt\n",
    "from ae_utils_exp import s_init, InpNorm1D, dsprites_norm, dsprites_inorm\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00559994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsprites import DSPRITES\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "ten_type = lambda x: torch.tensor(x, dtype=torch.float)\n",
    "flatten = lambda x: x.view(-1)\n",
    "chan_insert = lambda x: x.unsqueeze(0)\n",
    "\n",
    "dataset = DSPRITES(path=\"../beamsynthesizer/data/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\", transform=Compose([ten_type, chan_insert]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp_bn = dsprites_norm = dsprites_inorm = torch.nn.Identity()\n",
    "from architectures import enc_dsprites_vae_fc as enc\n",
    "from architectures import dec_dsprites_vae_fc as dec\n",
    "\n",
    "ae = VAE_BASED_MODEL(inp_bn, enc(lat=n_lat), dec(lat=n_lat), device, z_dim=n_lat, inp_inorm=dsprites_inorm, rec_dstr='bernoulli')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fb753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_loss, kl_loss = \\\n",
    "    ae.fit(dataset, 200, beta=beta, batch_per_group=20, batch_size=batch_size, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curves on a log scale\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].set_ylabel(\"$log_{10}$(Reconstruction Loss)\")\n",
    "ax[1].set_ylabel(\"$log_{10}$(KL Loss)\")\n",
    "ax[0].set_xlabel(\"Group\")\n",
    "ax[1].set_xlabel(\"Group\")\n",
    "ax[0].plot(np.log10(rec_loss), linewidth=2, label='Reconstruction')\n",
    "ax[1].plot(np.log10(kl_loss), linewidth=2, label='KL')\n",
    "ax[0].grid(True, which='both', ls='-')\n",
    "ax[1].grid(True, which='both', ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81e872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt_batch_size=200\n",
    "num_to_plot=20\n",
    "z_scores, std_scores, inp, rec = ae.record_latent_space(dataset, batch_size=plt_batch_size, n_batches=5)\n",
    "\n",
    "inp = inp.view(-1, 64, 64).cpu().numpy()\n",
    "rec = rec.view(-1, 64, 64).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, num_to_plot, figsize=(20, 4))\n",
    "for i in range(num_to_plot):\n",
    "    axes[0][i].imshow(inp[i], cmap='gray')\n",
    "    axes[1][i].imshow(rec[i], cmap='gray')\n",
    "    axes[0][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    axes[1][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06883920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine base z_scores\n",
    "ind = 0\n",
    "z_base = z_scores[ind]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axes[0].imshow(inp[ind], cmap='gray')\n",
    "axes[0].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "axes[1].imshow(rec[ind], cmap='gray')\n",
    "axes[1].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92be45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# decode\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 8))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i].min()\n",
    "        _max = z_scores[:, i].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min > 0.3:\n",
    "                z = z_base.clone()\n",
    "                z[i] = variation[j]\n",
    "                im = dsprites_inorm(ae.dec(z.to(ae.device))).view(64,64).cpu().numpy()\n",
    "                axes[i][j].imshow(im, cmap='gray', vmin=0.0, vmax=1.)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 8))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i + ae.z_dim//2].min()\n",
    "        _max = z_scores[:, i + ae.z_dim//2].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min > 0.3:\n",
    "                z = z_base.clone()\n",
    "                z[i + ae.z_dim//2] = variation[j]\n",
    "                im = dsprites_inorm(ae.dec(z.to(ae.device))).view(64, 64).cpu().numpy()\n",
    "                axes[i][j].imshow(im, cmap='gray', vmin=0.0, vmax=1.)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of learned latent features\n",
    "ave_vars = std_scores.square().mean(dim=0)\n",
    "mu_var = z_scores.var(dim=0)\n",
    "print(\"BetaVAE Count: \", (ave_vars <= 0.8).sum().item())\n",
    "z_max = z_scores.max(dim=0)[0]\n",
    "z_min = z_scores.min(dim=0)[0]\n",
    "print(\"FactorVAE, BetaTCVAE Count: \", (z_max - z_min >= 2.).sum().item())\n",
    "print(\"Seed \", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ae_utils_exp import DisentanglementMetric as DM\n",
    "dm = DM(n_lat, 4, lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18787a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the disentanglement metric linear classifier\n",
    "n_groups = 3000\n",
    "batch_per_group = 20\n",
    "bsize = 100\n",
    "losses = torch.zeros(n_groups)\n",
    "for i in range(n_groups):\n",
    "    loss = 0.\n",
    "    for j in range(batch_per_group):\n",
    "        # construct the batch\n",
    "        # randomly choose a data generating factor to hold constant, and create batches\n",
    "        const_dgf, batch_tup1, batch_tup2 = dataset.sample_latent_dm(bsize)\n",
    "        # push batches through the autoencoder\n",
    "        out1 = ae(batch_tup1[0].to(device))\n",
    "        z1 = ae.mu.detach()\n",
    "        out2 = ae(batch_tup2[0].to(device))\n",
    "        z2 = ae.mu.detach()\n",
    "        z_diff = (z1 - z2).abs()\n",
    "        # train on batch. min dgf is 2\n",
    "        loss += dm.fit_batch(const_dgf - 2, z_diff.cpu())\n",
    "    losses[i] = loss/batch_per_group\n",
    "    if i % 500 == 0:\n",
    "        print(i)\n",
    "    if i == int(0.95*n_groups):\n",
    "        dm.set_lr(0.05)\n",
    "plt.figure()\n",
    "plt.plot(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "bsize = 100\n",
    "n_correct = 0\n",
    "for i in range(n_iterations):\n",
    "    # construct the batch\n",
    "    # randomly choose a data generating factor to hold constant, and create batches\n",
    "    const_dgf, batch_tup1, batch_tup2 = dataset.sample_latent_dm(bsize)\n",
    "    # push batches through the autoencoder\n",
    "    out1 = ae(batch_tup1[0].to(device))\n",
    "    z1 = ae.mu.detach()\n",
    "    out2 = ae(batch_tup2[0].to(device))\n",
    "    z2 = ae.mu.detach()\n",
    "    z_diff = (z1 - z2).abs()\n",
    "    # batch is now constructed\n",
    "    prediction = dm(z_diff.mean(dim=0).unsqueeze(0).cpu())\n",
    "    n_correct += 1. if prediction == const_dgf - 2 else 0.\n",
    "    #print(prediction.item(), const_dgf - 2)\n",
    "print(\"Acc: {:1.1f}\".format(n_correct/n_iterations*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
