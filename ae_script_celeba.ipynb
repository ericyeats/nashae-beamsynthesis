{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd51fb3e",
   "metadata": {},
   "source": [
    "# NashAE CelebA\n",
    "### Overview\n",
    "This script is used to train a NashAE or AE (NashAE, $\\lambda=0$) on the CelebA dataset, then save it. The script will train a NashAE on a fixed amount of data using the hyperparameters defined in the cell below. The script will train the network with the given hyperparameters, compare original data with reconstructions, plot true latent variables against their predictions, create images of latent traversals, and save the model.\n",
    "\n",
    "### Instructions\n",
    "Set hyperparameters for the run in the cell below. Then, hit Run All on the jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe16cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SELECT A SEED ##############\n",
    "\n",
    "seed = 55\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "####### SELECT HYPERPARAMETERS ###########\n",
    "ar = 0.2 # adversarial ratio (\\lambda)\n",
    "batch_size = 200 # batch size used for training\n",
    "n_lat = 32 # number of latent features used for training\n",
    "lr = 0.001 # learning rate for training\n",
    "\n",
    "savename = \"./models/celeba_ae_lr1e-3_seed{}_ar{}.pt\".format(seed, ar) # savename for the trained model\n",
    "\n",
    "print(\"Seed: \", seed)\n",
    "print(\"Batch Size: \", batch_size)\n",
    "print(\"LR: \", lr)\n",
    "print(\"AdvRatio: \", ar)\n",
    "print(\"Savename: \", savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ae_utils_exp import s_init, AutoEncoder, multi_t\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00559994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CelebA\n",
    "import torchvision.transforms as tforms\n",
    "\n",
    "tform = tforms.Compose([tforms.Resize(96), tforms.CenterCrop(64), tforms.ToTensor()])\n",
    "\n",
    "dataset = CelebA(root='../beamsynthesizer/data', split='all', download=False, transform=tform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ae_utils_exp import celeba_norm, celeba_inorm\n",
    "inp_bn = celeba_norm\n",
    "from architectures import enc_celeba_small as enc\n",
    "from architectures import dec_celeba_small as dec\n",
    "ae = AutoEncoder(inp_bn, enc(lat=n_lat, inp_chan=3), dec(lat=n_lat, inp_chan=3), device, z_dim=n_lat, inp_inorm=celeba_inorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_loss, adv_loss, pred_loss = \\\n",
    "    ae.fit(dataset, 200, batch_per_group=20, batch_size=batch_size, lr=lr, ar=ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 3))\n",
    "# plot the loss curves on a log scale\n",
    "ax[0].set_ylabel(\"$log_{10}$(MSE Loss)\")\n",
    "ax[0].set_xlabel(\"Group\")\n",
    "ax[0].plot(np.log10(rec_loss), linewidth=2, label='Reconstruction')\n",
    "ax[0].plot(np.log10(pred_loss), linewidth=2, label='Predictor')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, which='both', ls='-')\n",
    "\n",
    "ax[1].set_ylabel(\"$log_{10}$ (Abs. Mean Cov.)\")\n",
    "ax[1].set_xlabel(\"Group\")\n",
    "ax[1].plot(np.log10(adv_loss.abs()/ae.z_dim), linewidth=2, label='Adversarial')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, which='both', ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show original data and reconstructions\n",
    "\n",
    "plt_batch_size=200\n",
    "num_to_plot=20\n",
    "z_scores, z_pred_scores, inp, rec = ae.record_latent_space(dataset, batch_size=plt_batch_size, n_batches=5)\n",
    "\n",
    "inp = multi_t(inp, 1, 3).clamp(0, 1).cpu().numpy()\n",
    "rec = multi_t(rec, 1, 3).clamp(0, 1).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, num_to_plot, figsize=(20, 4))\n",
    "for i in range(num_to_plot):\n",
    "    axes[0][i].imshow(inp[i])\n",
    "    axes[1][i].imshow(rec[i])\n",
    "    axes[0][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    axes[1][i].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot true latent variables against their predictions\n",
    "\n",
    "from ae_utils_exp import covariance\n",
    "# plot the latent space against itself\n",
    "fig, axes = plt.subplots(4, ae.z_dim//4, figsize=(24, 8))\n",
    "rho2_agg = 0.\n",
    "for ind in range(ae.z_dim):\n",
    "    i = ind // (ae.z_dim//4)\n",
    "    j = ind % (ae.z_dim//4)\n",
    "    axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "    axes[i][j].scatter(z_scores[..., ind], z_pred_scores[..., ind])\n",
    "    axes[i][j].set_xlim((-0.05, 1.05))\n",
    "    axes[i][j].set_ylim((-0.05, 1.05))\n",
    "    cov = covariance(z_scores[..., ind], z_pred_scores[..., ind]).item()\n",
    "    std = z_scores[..., ind].std(dim=0).item()\n",
    "    std_p = z_pred_scores[..., ind].std(dim=0).item()\n",
    "    rho2 = 0.\n",
    "    if std > 0.01 and std_p > 0.:\n",
    "        rho2 = (cov/(std*std_p))**2\n",
    "    rho2_agg += rho2\n",
    "    axes[i][j].set_title(\"R2: {:1.3f}\".format(rho2))\n",
    "print(rho2_agg/ae.z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06883920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base image used for traversals\n",
    "\n",
    "from ae_utils_exp import InvNorm\n",
    "\n",
    "invn = celeba_inorm\n",
    "\n",
    "# determine base z_scores\n",
    "ind = 2\n",
    "z_base = z_scores[ind]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axes[0].imshow(inp[ind], cmap='gray')\n",
    "axes[0].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "axes[1].imshow(rec[ind], cmap='gray')\n",
    "axes[1].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92be45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# decode traversals of the base latent encoding. omit traversals if their max-min range is less than 0.2\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 24))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i].min()\n",
    "        _max = z_scores[:, i].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min >= 0.2:\n",
    "                z = z_base.clone()\n",
    "                z[i] = variation[j]\n",
    "                im = multi_t(invn(ae.dec(z.to(ae.device))), 1, 3).clamp(0, 1).squeeze().cpu().numpy()\n",
    "                axes[i][j].imshow(im, cmap='gray')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode traversals of the base latent encoding. omit traversals if their max-min range is less than 0.2\n",
    "fig, axes = plt.subplots(ae.z_dim//2, 10, figsize=(16, 24))\n",
    "with torch.no_grad():\n",
    "    for i in range(ae.z_dim//2):\n",
    "        _min = z_scores[:, i + ae.z_dim//2].min()\n",
    "        _max = z_scores[:, i + ae.z_dim//2].max()\n",
    "        variation = torch.linspace(_min, _max, steps=10)\n",
    "        for j in range(len(variation)):\n",
    "            axes[i][j].tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, left=False, labelleft=False)\n",
    "            if _max - _min >= 0.2:\n",
    "                z = z_base.clone()\n",
    "                z[i + ae.z_dim//2] = variation[j]\n",
    "                im = multi_t(invn(ae.dec(z.to(ae.device))), 1, 3).clamp(0,1).squeeze().cpu().numpy()\n",
    "                axes[i][j].imshow(im, cmap='gray')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ae.state_dict(), savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ca70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
